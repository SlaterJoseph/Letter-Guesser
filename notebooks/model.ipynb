{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baac3d5d-7d09-432e-83e9-1ddaa493f408",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = pd.read_csv('../data/emnist-letters-train.csv')\n",
    "test = pd.read_csv('../data/emnist-letters-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "021ffe4e-4bbc-4927-bb4e-d6eb983387c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'A / a',\n",
       " 2: 'B / b',\n",
       " 3: 'C / c',\n",
       " 4: 'D / d',\n",
       " 5: 'E / e',\n",
       " 6: 'F / f',\n",
       " 7: 'G / g',\n",
       " 8: 'H / h',\n",
       " 9: 'I / i',\n",
       " 10: 'J / j',\n",
       " 11: 'K / k',\n",
       " 12: 'L / l',\n",
       " 13: 'M / m',\n",
       " 14: 'N / n',\n",
       " 15: 'O / o',\n",
       " 16: 'P / p',\n",
       " 17: 'Q / q',\n",
       " 18: 'R / r',\n",
       " 19: 'S / s',\n",
       " 20: 'T / t',\n",
       " 21: 'U / u',\n",
       " 22: 'V / v',\n",
       " 23: 'W / w',\n",
       " 24: 'X / x',\n",
       " 25: 'Y / y',\n",
       " 26: 'Z / z'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappings = {}\n",
    "\n",
    "with open('../data/emnist-letters-mapping.txt') as file:\n",
    "    for line in file:\n",
    "        arr = line.strip().split(' ')\n",
    "        mappings[int(arr[0])] = chr(int(arr[1])) + ' / ' + chr(int(arr[2]))\n",
    "        \n",
    "mappings        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0080682-d3a1-4202-a032-59fc38cbc13f",
   "metadata": {},
   "source": [
    "### Preprocessing the data\n",
    "\n",
    "1. Merging the data so we can do repetetive sampling\n",
    "2. Splitting up labels and images\n",
    "3. Preprocessing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16131ffb-0de6-4f1d-913b-9da68df99fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "training.columns = ['label'] +[f'feature_{i}' for i in range(1, training.shape[1])]\n",
    "test.columns = ['label'] +[f'feature_{i}' for i in range(1, test.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cef78a68-c68e-4a1d-a572-a193b4cf12a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((88799, 785), (14799, 785), (103598, 785))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([training, test], axis=0)\n",
    "training.shape, test.shape, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e7bb16e-1055-4a91-9df4-22f70b6bd41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['label']\n",
    "images = data.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9321aec4-2dbc-4f05-8fb9-e734e36f405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.values.reshape(-1, 28, 28, 1)\n",
    "images = images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47ac4ea2-3d75-4c7d-b30a-5ef43396c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(images, labels, test_size=0.2, random_state=253)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=253)\n",
    "\n",
    "y_train -= 1\n",
    "y_val -= 1\n",
    "y_test -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18efe060-b0e3-4cb4-85e1-0229c07e38dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique training labels: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25]\n",
      "Unique validation labels: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25]\n",
      "Unique test labels: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique training labels:\", np.unique(y_train))\n",
    "print(\"Unique validation labels:\", np.unique(y_val))\n",
    "print(\"Unique test labels:\", np.unique(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d938a2e7-cd87-40cb-85d7-6e564264a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train, 26)\n",
    "y_val = to_categorical(y_val, 26)\n",
    "y_test = to_categorical(y_test, 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15094538-1f99-4576-8af5-196ee63c2dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def create_model():\n",
    "    model = models.Sequential([\n",
    "        layers.InputLayer(shape=(28, 28, 1)),\n",
    "        layers.Conv2D(32, (2, 2), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(26, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2d49edb-15c4-4dec-a8dd-1a7ce248311c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/letter-guesser/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2072/2072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.5141 - loss: 1.6147 - val_accuracy: 0.8852 - val_loss: 0.3567\n",
      "Epoch 2/20\n",
      "\u001b[1m2072/2072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 8ms/step - accuracy: 0.8185 - loss: 0.5780 - val_accuracy: 0.9020 - val_loss: 0.2913\n",
      "Epoch 3/20\n",
      "\u001b[1m2072/2072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.8603 - loss: 0.4368 - val_accuracy: 0.9175 - val_loss: 0.2576\n",
      "Epoch 4/20\n",
      "\u001b[1m2072/2072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.8815 - loss: 0.3743 - val_accuracy: 0.9225 - val_loss: 0.2397\n",
      "Epoch 5/20\n",
      "\u001b[1m2072/2072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.8910 - loss: 0.3409 - val_accuracy: 0.9256 - val_loss: 0.2318\n",
      "Epoch 6/20\n",
      "\u001b[1m2072/2072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.9004 - loss: 0.3077 - val_accuracy: 0.9208 - val_loss: 0.2418\n",
      "Epoch 7/20\n",
      "\u001b[1m2072/2072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.9047 - loss: 0.2938 - val_accuracy: 0.9280 - val_loss: 0.2300\n",
      "Epoch 8/20\n",
      "\u001b[1m2072/2072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9140 - loss: 0.2635 - val_accuracy: 0.9286 - val_loss: 0.2201\n",
      "Epoch 9/20\n",
      "\u001b[1m2072/2072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9134 - loss: 0.2601 - val_accuracy: 0.9312 - val_loss: 0.2124\n",
      "Epoch 10/20\n",
      "\u001b[1m2072/2072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9185 - loss: 0.2397 - val_accuracy: 0.9275 - val_loss: 0.2178\n",
      "Epoch 11/20\n",
      "\u001b[1m2072/2072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9235 - loss: 0.2307 - val_accuracy: 0.9300 - val_loss: 0.2206\n",
      "Epoch 12/20\n",
      "\u001b[1m2072/2072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9231 - loss: 0.2276 - val_accuracy: 0.9306 - val_loss: 0.2360\n",
      "Epoch 13/20\n",
      "\u001b[1m2072/2072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9255 - loss: 0.2191 - val_accuracy: 0.9332 - val_loss: 0.2312\n",
      "Epoch 14/20\n",
      "\u001b[1m2072/2072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9267 - loss: 0.2118 - val_accuracy: 0.9323 - val_loss: 0.2329\n",
      "Epoch 15/20\n",
      "\u001b[1m2072/2072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9289 - loss: 0.1998 - val_accuracy: 0.9323 - val_loss: 0.2299\n",
      "Epoch 16/20\n",
      "\u001b[1m2072/2072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9311 - loss: 0.1944 - val_accuracy: 0.9316 - val_loss: 0.2410\n",
      "Epoch 17/20\n",
      "\u001b[1m2072/2072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9338 - loss: 0.1844 - val_accuracy: 0.9321 - val_loss: 0.2347\n",
      "Epoch 18/20\n",
      "\u001b[1m2072/2072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9346 - loss: 0.1866 - val_accuracy: 0.9330 - val_loss: 0.2360\n",
      "Epoch 19/20\n",
      "\u001b[1m2072/2072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9362 - loss: 0.1738 - val_accuracy: 0.9341 - val_loss: 0.2430\n",
      "Epoch 20/20\n",
      "\u001b[1m2072/2072\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9351 - loss: 0.1793 - val_accuracy: 0.9326 - val_loss: 0.2385\n",
      "Test Accuracy: 0.9304\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=20,  \n",
    "                    batch_size=32, \n",
    "                    validation_data=(X_val, y_val), \n",
    "                    verbose=1)  \n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88519302-4542-4f9e-80e8-3fef85a5e1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('../model/letter_predicter.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
